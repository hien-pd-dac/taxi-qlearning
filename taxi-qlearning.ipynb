{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1: Import libraries\n",
    "- Numpy for Q Table\n",
    "- OpenAI Gym for Environment\n",
    "- Random for random number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2: Init env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : :\u001b[43m \u001b[0m|\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Taxi-v2\")\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tính không gian states và actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "action_space = env.action_space.n\n",
    "print(action_space)\n",
    "state_space = env.observation_space.n\n",
    "print(state_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Khởi tạo Q-Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "q_table = np.zeros(action_space*state_space).reshape(state_space, action_space)\n",
    "print(q_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Khởi tạo tham số epsilon, decay_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "decay_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traning(max_episodes, max_steps, learning_rate, gamma, epsilon):\n",
    "    show_episodes = [0, 99, 499, 999, 49999]\n",
    "    for i_episode in range(max_episodes):\n",
    "        sum_reward = 0\n",
    "        cur_state = env.reset()\n",
    "        done = False\n",
    "        if i_episode in show_episodes:\n",
    "            print('Start episode {}:'.format(i_episode))\n",
    "            env.render()\n",
    "            print('state={}'.format(cur_state))\n",
    "        \n",
    "        for i_step in range(max_steps):\n",
    "            if (random.random() < epsilon):\n",
    "#               exploration \n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "#               exploitation\n",
    "                action = np.argmax(q_table[cur_state, :])\n",
    "#           simulate action, observe new_state, reward,..\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "            if i_episode in show_episodes:\n",
    "                print('Step {}:'.format(i_step))\n",
    "                print('action={}, reward={}, new_state={}'.format(action, reward, new_state))\n",
    "                print('{}=(1-{})*{}+{}*({}+{}*{})'.format((1 - learning_rate) * q_table[cur_state, action] + \\\n",
    "                learning_rate * (reward + gamma * np.max(q_table[new_state])), learning_rate,\n",
    "                                                         q_table[cur_state, action], learning_rate, reward,\n",
    "                                                         gamma, np.max(q_table[new_state])))\n",
    "                env.render()\n",
    "#           update q-table     \n",
    "            q_table[cur_state, action] = (1 - learning_rate) * q_table[cur_state, action] + \\\n",
    "                learning_rate * (reward + gamma * np.max(q_table[new_state]))\n",
    "#           update state\n",
    "            cur_state = new_state\n",
    "            sum_reward += reward\n",
    "            \n",
    "            if done or i_step == max_steps-1:\n",
    "                if i_episode in show_episodes:\n",
    "                    print('End episode {}! with sum_reward:{}'.format(i_episode, sum_reward))\n",
    "                break\n",
    "#           update epsilon(k)        \n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*(i_episode+1))\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Playing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playing(episode_num):\n",
    "    \n",
    "    for i_episode in range(episode_num):\n",
    "        sum_reward = 0\n",
    "        done = False\n",
    "        cur_state = env.reset()\n",
    "        print('Start episode {}:'.format(i_episode))\n",
    "        env.render()\n",
    "        \n",
    "        for i_step in range(30):\n",
    "            import time\n",
    "            time.sleep(1)\n",
    "            print('step {}:'.format(i_step))\n",
    "            action = np.argmax(q_table[cur_state])\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "            env.render()\n",
    "            cur_state = new_state\n",
    "            sum_reward += reward\n",
    "            if (done):\n",
    "                print('End episode {}! with sum_reward={}'.format(i_episode, sum_reward))\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lựa chọn hyperparameter:\n",
    "- max_episodes = 50000\n",
    "- max_steps = 100\n",
    "- learning_rate = 0.7\n",
    "- gamma = 0.681\n",
    "- epsilon = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start episode 0:\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "\n",
      "state=103\n",
      "Step 0:\n",
      "action=4, reward=-10, new_state=103\n",
      "-7.0=(1-0.7)*0.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 1:\n",
      "action=5, reward=-10, new_state=103\n",
      "-7.0=(1-0.7)*0.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Step 2:\n",
      "action=0, reward=-1, new_state=203\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 3:\n",
      "action=3, reward=-1, new_state=203\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 4:\n",
      "action=3, reward=-1, new_state=203\n",
      "-0.9099999999999999=(1-0.7)*-0.7+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 5:\n",
      "action=3, reward=-1, new_state=203\n",
      "-0.973=(1-0.7)*-0.9099999999999999+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 6:\n",
      "action=1, reward=-1, new_state=103\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 7:\n",
      "action=3, reward=-1, new_state=103\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 8:\n",
      "action=5, reward=-10, new_state=103\n",
      "-9.100000000000001=(1-0.7)*-7.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Step 9:\n",
      "action=2, reward=-1, new_state=123\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 10:\n",
      "action=4, reward=-10, new_state=123\n",
      "-7.0=(1-0.7)*0.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 11:\n",
      "action=0, reward=-1, new_state=223\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 12:\n",
      "action=0, reward=-1, new_state=323\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| |\u001b[43m \u001b[0m: | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 13:\n",
      "action=4, reward=-10, new_state=323\n",
      "-7.0=(1-0.7)*0.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| |\u001b[43m \u001b[0m: | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 14:\n",
      "action=2, reward=-1, new_state=343\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | :\u001b[43m \u001b[0m| : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 15:\n",
      "action=1, reward=-1, new_state=243\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 16:\n",
      "action=0, reward=-1, new_state=343\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | :\u001b[43m \u001b[0m| : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 17:\n",
      "action=1, reward=-1, new_state=243\n",
      "-0.9099999999999999=(1-0.7)*-0.7+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 18:\n",
      "action=5, reward=-10, new_state=243\n",
      "-7.0=(1-0.7)*0.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Step 19:\n",
      "action=1, reward=-1, new_state=143\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 20:\n",
      "action=5, reward=-10, new_state=143\n",
      "-7.0=(1-0.7)*0.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Step 21:\n",
      "action=0, reward=-1, new_state=243\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 22:\n",
      "action=1, reward=-1, new_state=143\n",
      "-0.9099999999999999=(1-0.7)*-0.7+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 23:\n",
      "action=4, reward=-10, new_state=143\n",
      "-7.0=(1-0.7)*0.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 24:\n",
      "action=3, reward=-1, new_state=123\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 25:\n",
      "action=0, reward=-1, new_state=223\n",
      "-0.9099999999999999=(1-0.7)*-0.7+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 26:\n",
      "action=3, reward=-1, new_state=203\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 27:\n",
      "action=5, reward=-10, new_state=203\n",
      "-7.0=(1-0.7)*0.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Step 28:\n",
      "action=0, reward=-1, new_state=303\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m| : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 29:\n",
      "action=2, reward=-1, new_state=303\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m| : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 30:\n",
      "action=3, reward=-1, new_state=303\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m| : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 31:\n",
      "action=0, reward=-1, new_state=403\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[43mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 32:\n",
      "action=1, reward=-1, new_state=303\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m| : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 33:\n",
      "action=3, reward=-1, new_state=303\n",
      "-0.9099999999999999=(1-0.7)*-0.7+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m| : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 34:\n",
      "action=5, reward=-10, new_state=303\n",
      "-7.0=(1-0.7)*0.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m| : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Step 35:\n",
      "action=3, reward=-1, new_state=303\n",
      "-0.973=(1-0.7)*-0.9099999999999999+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m| : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 36:\n",
      "action=3, reward=-1, new_state=303\n",
      "-0.9919=(1-0.7)*-0.973+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m| : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 37:\n",
      "action=0, reward=-1, new_state=403\n",
      "-0.9099999999999999=(1-0.7)*-0.7+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[43mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 38:\n",
      "action=1, reward=-1, new_state=303\n",
      "-0.9099999999999999=(1-0.7)*-0.7+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m| : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 39:\n",
      "action=1, reward=-1, new_state=203\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 40:\n",
      "action=1, reward=-1, new_state=103\n",
      "-0.9099999999999999=(1-0.7)*-0.7+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 41:\n",
      "action=0, reward=-1, new_state=203\n",
      "-0.9099999999999999=(1-0.7)*-0.7+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 42:\n",
      "action=2, reward=-1, new_state=223\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 43:\n",
      "action=4, reward=-10, new_state=223\n",
      "-7.0=(1-0.7)*0.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 44:\n",
      "action=3, reward=-1, new_state=203\n",
      "-0.9099999999999999=(1-0.7)*-0.7+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 45:\n",
      "action=3, reward=-1, new_state=203\n",
      "-0.9919=(1-0.7)*-0.973+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 46:\n",
      "action=2, reward=-1, new_state=223\n",
      "-0.9099999999999999=(1-0.7)*-0.7+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 47:\n",
      "action=4, reward=-10, new_state=223\n",
      "-9.100000000000001=(1-0.7)*-7.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 48:\n",
      "action=2, reward=-1, new_state=243\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 49:\n",
      "action=0, reward=-1, new_state=343\n",
      "-0.9099999999999999=(1-0.7)*-0.7+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | :\u001b[43m \u001b[0m| : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 50:\n",
      "action=0, reward=-1, new_state=443\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| :\u001b[43m \u001b[0m|\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 51:\n",
      "action=4, reward=-10, new_state=443\n",
      "-7.0=(1-0.7)*0.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| :\u001b[43m \u001b[0m|\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 52:\n",
      "action=5, reward=-10, new_state=443\n",
      "-7.0=(1-0.7)*0.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| :\u001b[43m \u001b[0m|\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Step 53:\n",
      "action=5, reward=-10, new_state=443\n",
      "-9.100000000000001=(1-0.7)*-7.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| :\u001b[43m \u001b[0m|\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Step 54:\n",
      "action=0, reward=-1, new_state=443\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| :\u001b[43m \u001b[0m|\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 55:\n",
      "action=4, reward=-10, new_state=443\n",
      "-9.100000000000001=(1-0.7)*-7.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| :\u001b[43m \u001b[0m|\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 56:\n",
      "action=1, reward=-1, new_state=343\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | :\u001b[43m \u001b[0m| : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 57:\n",
      "action=4, reward=-10, new_state=343\n",
      "-7.0=(1-0.7)*0.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | :\u001b[43m \u001b[0m| : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 58:\n",
      "action=1, reward=-1, new_state=243\n",
      "-0.973=(1-0.7)*-0.9099999999999999+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 59:\n",
      "action=2, reward=-1, new_state=263\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : :\u001b[43m \u001b[0m: |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 60:\n",
      "action=2, reward=-1, new_state=283\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : :\u001b[43m \u001b[0m|\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 61:\n",
      "action=0, reward=-1, new_state=383\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | :\u001b[43m \u001b[0m|\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 62:\n",
      "action=1, reward=-1, new_state=283\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : :\u001b[43m \u001b[0m|\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 63:\n",
      "action=1, reward=-1, new_state=183\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : : : :\u001b[43m \u001b[0m|\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 64:\n",
      "action=1, reward=-1, new_state=83\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :\u001b[43mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 65:\n",
      "action=1, reward=-1, new_state=83\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :\u001b[43mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 66:\n",
      "action=3, reward=-1, new_state=63\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | :\u001b[43m \u001b[0m:G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 67:\n",
      "action=3, reward=-1, new_state=43\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: |\u001b[43m \u001b[0m: :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 68:\n",
      "action=2, reward=-1, new_state=63\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | :\u001b[43m \u001b[0m:G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 69:\n",
      "action=3, reward=-1, new_state=43\n",
      "-0.9099999999999999=(1-0.7)*-0.7+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: |\u001b[43m \u001b[0m: :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 70:\n",
      "action=0, reward=-1, new_state=143\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 71:\n",
      "action=3, reward=-1, new_state=123\n",
      "-0.9099999999999999=(1-0.7)*-0.7+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 72:\n",
      "action=5, reward=-10, new_state=123\n",
      "-7.0=(1-0.7)*0.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Step 73:\n",
      "action=4, reward=-10, new_state=123\n",
      "-9.100000000000001=(1-0.7)*-7.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 74:\n",
      "action=1, reward=-1, new_state=23\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m:\u001b[43m \u001b[0m| : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 75:\n",
      "action=2, reward=-1, new_state=23\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m:\u001b[43m \u001b[0m| : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 76:\n",
      "action=4, reward=-10, new_state=23\n",
      "-7.0=(1-0.7)*0.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m:\u001b[43m \u001b[0m| : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 77:\n",
      "action=3, reward=-1, new_state=3\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 78:\n",
      "action=4, reward=-1, new_state=19\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[42mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 79:\n",
      "action=4, reward=-10, new_state=19\n",
      "-7.0=(1-0.7)*0.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[42mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 80:\n",
      "action=4, reward=-10, new_state=19\n",
      "-9.100000000000001=(1-0.7)*-7.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[42mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 81:\n",
      "action=3, reward=-1, new_state=19\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[42mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 82:\n",
      "action=4, reward=-10, new_state=19\n",
      "-9.73=(1-0.7)*-9.100000000000001+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[42mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 83:\n",
      "action=4, reward=-10, new_state=19\n",
      "-9.919=(1-0.7)*-9.73+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[42mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 84:\n",
      "action=4, reward=-10, new_state=19\n",
      "-9.9757=(1-0.7)*-9.919+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[42mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 85:\n",
      "action=0, reward=-1, new_state=119\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 86:\n",
      "action=4, reward=-10, new_state=119\n",
      "-7.0=(1-0.7)*0.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 87:\n",
      "action=3, reward=-1, new_state=119\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 88:\n",
      "action=2, reward=-1, new_state=139\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| :\u001b[42m_\u001b[0m: : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 89:\n",
      "action=5, reward=-10, new_state=139\n",
      "-7.0=(1-0.7)*0.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| :\u001b[42m_\u001b[0m: : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Step 90:\n",
      "action=5, reward=-10, new_state=139\n",
      "-9.100000000000001=(1-0.7)*-7.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| :\u001b[42m_\u001b[0m: : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Step 91:\n",
      "action=5, reward=-10, new_state=139\n",
      "-9.73=(1-0.7)*-9.100000000000001+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| :\u001b[42m_\u001b[0m: : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Step 92:\n",
      "action=0, reward=-1, new_state=239\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| :\u001b[42m_\u001b[0m: : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 93:\n",
      "action=1, reward=-1, new_state=139\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| :\u001b[42m_\u001b[0m: : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 94:\n",
      "action=5, reward=-10, new_state=139\n",
      "-9.919=(1-0.7)*-9.73+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| :\u001b[42m_\u001b[0m: : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Step 95:\n",
      "action=1, reward=-1, new_state=39\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|R:\u001b[42m_\u001b[0m| : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 96:\n",
      "action=3, reward=-1, new_state=19\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|\u001b[42mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 97:\n",
      "action=0, reward=-1, new_state=119\n",
      "-0.9099999999999999=(1-0.7)*-0.7+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 98:\n",
      "action=5, reward=-10, new_state=119\n",
      "-7.0=(1-0.7)*0.0+0.7*(-10+0.681*0.0)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Step 99:\n",
      "action=0, reward=-1, new_state=219\n",
      "-0.7=(1-0.7)*0.0+0.7*(-1+0.681*0.0)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "End episode 0! with sum_reward:-379\n",
      "Start episode 99:\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| |\u001b[43m \u001b[0m: | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "\n",
      "state=331\n",
      "Step 0:\n",
      "action=3, reward=-1, new_state=331\n",
      "-1.24369=(1-0.7)*-0.7+0.7*(-1+0.681*-0.7)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| |\u001b[43m \u001b[0m: | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 1:\n",
      "action=4, reward=-10, new_state=331\n",
      "-10.5129682=(1-0.7)*-10.163796999999999+0.7*(-10+0.681*-0.973)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| |\u001b[43m \u001b[0m: | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 2:\n",
      "action=1, reward=-1, new_state=231\n",
      "-1.46473873=(1-0.7)*-0.973+0.7*(-1+0.681*-0.9919)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 3:\n",
      "action=1, reward=-1, new_state=131\n",
      "-1.6771997599=(1-0.7)*-0.9919+0.7*(-1+0.681*-1.425697)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 4:\n",
      "action=4, reward=-10, new_state=131\n",
      "-10.409629759900001=(1-0.7)*-9.100000000000001+0.7*(-10+0.681*-1.425697)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 5:\n",
      "action=2, reward=-1, new_state=151\n",
      "-1.603250719=(1-0.7)*-1.425697+0.7*(-1+0.681*-0.9975700000000001)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 6:\n",
      "action=5, reward=-10, new_state=151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10.494648619=(1-0.7)*-10.06369+0.7*(-10+0.681*-0.9975700000000001)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Step 7:\n",
      "action=5, reward=-10, new_state=151\n",
      "-10.6239362047=(1-0.7)*-10.494648619+0.7*(-10+0.681*-0.9975700000000001)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Step 8:\n",
      "action=4, reward=-10, new_state=151\n",
      "-9.575541619=(1-0.7)*-7.0+0.7*(-10+0.681*-0.9975700000000001)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 9:\n",
      "action=3, reward=-1, new_state=131\n",
      "-1.6816036489000001=(1-0.7)*-0.9975700000000001+0.7*(-1+0.681*-1.431367)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 10:\n",
      "action=0, reward=-1, new_state=231\n",
      "-1.807669213=(1-0.7)*-1.6159002999999998+0.7*(-1+0.681*-1.3066900000000001)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 11:\n",
      "action=0, reward=-1, new_state=331\n",
      "-1.6848740229999999=(1-0.7)*-1.3066900000000001+0.7*(-1+0.681*-1.24369)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| |\u001b[43m \u001b[0m: | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 12:\n",
      "action=0, reward=-1, new_state=431\n",
      "-1.665974023=(1-0.7)*-1.24369+0.7*(-1+0.681*-1.24369)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m|\u001b[43m \u001b[0m: |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 13:\n",
      "action=3, reward=-1, new_state=431\n",
      "-1.665974023=(1-0.7)*-1.24369+0.7*(-1+0.681*-1.24369)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m|\u001b[43m \u001b[0m: |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 14:\n",
      "action=1, reward=-1, new_state=331\n",
      "-1.665974023=(1-0.7)*-1.24369+0.7*(-1+0.681*-1.24369)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| |\u001b[43m \u001b[0m: | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 15:\n",
      "action=0, reward=-1, new_state=431\n",
      "-1.89373826887=(1-0.7)*-1.665974023+0.7*(-1+0.681*-1.4557290999999999)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m|\u001b[43m \u001b[0m: |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 16:\n",
      "action=5, reward=-10, new_state=431\n",
      "-9.79394606197=(1-0.7)*-7.0+0.7*(-10+0.681*-1.4557290999999999)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m|\u001b[43m \u001b[0m: |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Step 17:\n",
      "action=2, reward=-1, new_state=451\n",
      "-1.783979953=(1-0.7)*-1.5369361+0.7*(-1+0.681*-1.3066900000000001)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| :\u001b[43m \u001b[0m|\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 18:\n",
      "action=0, reward=-1, new_state=451\n",
      "-1.7449382230000001=(1-0.7)*-1.406797+0.7*(-1+0.681*-1.3066900000000001)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| :\u001b[43m \u001b[0m|\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 19:\n",
      "action=3, reward=-1, new_state=431\n",
      "-1.78595306197=(1-0.7)*-1.3066900000000001+0.7*(-1+0.681*-1.4557290999999999)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m|\u001b[43m \u001b[0m: |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 20:\n",
      "action=0, reward=-1, new_state=431\n",
      "-1.8306647919699999=(1-0.7)*-1.4557290999999999+0.7*(-1+0.681*-1.4557290999999999)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m|\u001b[43m \u001b[0m: |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 21:\n",
      "action=1, reward=-1, new_state=331\n",
      "-1.7926592299=(1-0.7)*-1.665974023+0.7*(-1+0.681*-1.24369)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| |\u001b[43m \u001b[0m: | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 22:\n",
      "action=1, reward=-1, new_state=231\n",
      "-1.8100417489000002=(1-0.7)*-1.46473873+0.7*(-1+0.681*-1.406797)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 23:\n",
      "action=2, reward=-1, new_state=251\n",
      "-1.714906123=(1-0.7)*-1.406797+0.7*(-1+0.681*-1.24369)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 24:\n",
      "action=0, reward=-1, new_state=351\n",
      "-1.665974023=(1-0.7)*-1.24369+0.7*(-1+0.681*-1.24369)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | :\u001b[43m \u001b[0m| : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 25:\n",
      "action=3, reward=-1, new_state=331\n",
      "-1.665974023=(1-0.7)*-1.24369+0.7*(-1+0.681*-1.24369)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| |\u001b[43m \u001b[0m: | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 26:\n",
      "action=3, reward=-1, new_state=331\n",
      "-1.665974023=(1-0.7)*-1.24369+0.7*(-1+0.681*-1.24369)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| |\u001b[43m \u001b[0m: | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 27:\n",
      "action=2, reward=-1, new_state=351\n",
      "-1.7737592299=(1-0.7)*-1.343797+0.7*(-1+0.681*-1.406797)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | :\u001b[43m \u001b[0m| : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 28:\n",
      "action=0, reward=-1, new_state=451\n",
      "-1.7926592299000002=(1-0.7)*-1.406797+0.7*(-1+0.681*-1.406797)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| :\u001b[43m \u001b[0m|\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 29:\n",
      "action=2, reward=-1, new_state=451\n",
      "-1.7926592299000002=(1-0.7)*-1.406797+0.7*(-1+0.681*-1.406797)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| :\u001b[43m \u001b[0m|\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 30:\n",
      "action=1, reward=-1, new_state=351\n",
      "-1.8283613299=(1-0.7)*-1.525804+0.7*(-1+0.681*-1.406797)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | :\u001b[43m \u001b[0m| : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 31:\n",
      "action=1, reward=-1, new_state=251\n",
      "-1.8637061688700003=(1-0.7)*-1.406797+0.7*(-1+0.681*-1.5558361)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 32:\n",
      "action=3, reward=-1, new_state=231\n",
      "-1.8463805898999999=(1-0.7)*-1.5558361+0.7*(-1+0.681*-1.425697)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 33:\n",
      "action=3, reward=-1, new_state=211\n",
      "-1.7205761229999998=(1-0.7)*-1.425697+0.7*(-1+0.681*-1.24369)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 34:\n",
      "action=3, reward=-1, new_state=211\n",
      "-1.665974023=(1-0.7)*-1.24369+0.7*(-1+0.681*-1.24369)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 35:\n",
      "action=4, reward=-10, new_state=211\n",
      "-9.722899123=(1-0.7)*-7.0+0.7*(-10+0.681*-1.3066900000000001)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 36:\n",
      "action=1, reward=-1, new_state=111\n",
      "-1.8103481368=(1-0.7)*-1.3066900000000001+0.7*(-1+0.681*-1.506904)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 37:\n",
      "action=0, reward=-1, new_state=211\n",
      "-1.8985200098641=(1-0.7)*-1.506904+0.7*(-1+0.681*-1.565867023)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 38:\n",
      "action=2, reward=-1, new_state=231\n",
      "-1.9696115855443297=(1-0.7)*-1.5669681999999998+0.7*(-1+0.681*-1.6771997599)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 39:\n",
      "action=1, reward=-1, new_state=131\n",
      "-1.8854925768700002=(1-0.7)*-1.6771997599+0.7*(-1+0.681*-1.431367)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 40:\n",
      "action=1, reward=-1, new_state=31\n",
      "-1.722277123=(1-0.7)*-1.431367+0.7*(-1+0.681*-1.24369)\n",
      "+---------+\n",
      "|R:\u001b[43m \u001b[0m| : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 41:\n",
      "action=1, reward=-1, new_state=31\n",
      "-1.665974023=(1-0.7)*-1.24369+0.7*(-1+0.681*-1.24369)\n",
      "+---------+\n",
      "|R:\u001b[43m \u001b[0m| : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 42:\n",
      "action=3, reward=-1, new_state=11\n",
      "-1.9210287384610003=(1-0.7)*-1.565867023+0.7*(-1+0.681*-1.57597783)\n",
      "+---------+\n",
      "|\u001b[43mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 43:\n",
      "action=2, reward=-1, new_state=31\n",
      "-1.765660372=(1-0.7)*-1.57597783+0.7*(-1+0.681*-1.24369)\n",
      "+---------+\n",
      "|R:\u001b[43m \u001b[0m| : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 44:\n",
      "action=2, reward=-1, new_state=31\n",
      "-1.665974023=(1-0.7)*-1.24369+0.7*(-1+0.681*-1.24369)\n",
      "+---------+\n",
      "|R:\u001b[43m \u001b[0m| : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 45:\n",
      "action=0, reward=-1, new_state=131\n",
      "-1.9504103546473=(1-0.7)*-1.6204691230000001+0.7*(-1+0.681*-1.603250719)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 46:\n",
      "action=0, reward=-1, new_state=231\n",
      "-2.0454802106641=(1-0.7)*-1.807669213+0.7*(-1+0.681*-1.6848740229999999)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 47:\n",
      "action=4, reward=-10, new_state=231\n",
      "-10.5331794467641=(1-0.7)*-9.100000000000001+0.7*(-10+0.681*-1.6848740229999999)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 48:\n",
      "action=0, reward=-1, new_state=331\n",
      "-1.9996320236641=(1-0.7)*-1.6848740229999999+0.7*(-1+0.681*-1.665974023)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| |\u001b[43m \u001b[0m: | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 49:\n",
      "action=3, reward=-1, new_state=331\n",
      "-1.9939620236641=(1-0.7)*-1.665974023+0.7*(-1+0.681*-1.665974023)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| |\u001b[43m \u001b[0m: | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 50:\n",
      "action=1, reward=-1, new_state=231\n",
      "-2.0605082735041=(1-0.7)*-1.8100417489000002+0.7*(-1+0.681*-1.714906123)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 51:\n",
      "action=0, reward=-1, new_state=331\n",
      "-2.1454406319925603=(1-0.7)*-1.9996320236641+0.7*(-1+0.681*-1.7737592299)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| |\u001b[43m \u001b[0m: | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 52:\n",
      "action=2, reward=-1, new_state=351\n",
      "-1.9951089195310003=(1-0.7)*-1.7737592299+0.7*(-1+0.681*-1.60054783)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | :\u001b[43m \u001b[0m| : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 53:\n",
      "action=1, reward=-1, new_state=251\n",
      "-2.0177981106010003=(1-0.7)*-1.8637061688700003+0.7*(-1+0.681*-1.5915382)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 54:\n",
      "action=1, reward=-1, new_state=151\n",
      "-1.8570912198999998=(1-0.7)*-1.5915382+0.7*(-1+0.681*-1.425697)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 55:\n",
      "action=0, reward=-1, new_state=251\n",
      "-1.9112228159233302=(1-0.7)*-1.425697+0.7*(-1+0.681*-1.6436201299)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 56:\n",
      "action=1, reward=-1, new_state=151\n",
      "-1.9367571258699998=(1-0.7)*-1.8570912198999998+0.7*(-1+0.681*-1.425697)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 57:\n",
      "action=2, reward=-1, new_state=171\n",
      "-1.96144557784=(1-0.7)*-1.8103481368+0.7*(-1+0.681*-1.506904)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : :\u001b[43m \u001b[0m: |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 58:\n",
      "action=2, reward=-1, new_state=191\n",
      "-1.9552506467640998=(1-0.7)*-1.506904+0.7*(-1+0.681*-1.6848740229999999)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : :\u001b[43m \u001b[0m|\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 59:\n",
      "action=1, reward=-1, new_state=91\n",
      "-1.7983292298999998=(1-0.7)*-1.6848740229999999+0.7*(-1+0.681*-1.24369)\n",
      "+---------+\n",
      "|R: | : :\u001b[43mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 60:\n",
      "action=1, reward=-1, new_state=91\n",
      "-1.665974023=(1-0.7)*-1.24369+0.7*(-1+0.681*-1.24369)\n",
      "+---------+\n",
      "|R: | : :\u001b[43mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 61:\n",
      "action=0, reward=-1, new_state=191\n",
      "-2.0776787938633303=(1-0.7)*-1.7437271299000001+0.7*(-1+0.681*-1.7926592299000002)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : :\u001b[43m \u001b[0m|\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 62:\n",
      "action=2, reward=-1, new_state=191\n",
      "-2.09235842386333=(1-0.7)*-1.7926592299000002+0.7*(-1+0.681*-1.7926592299000002)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : :\u001b[43m \u001b[0m|\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 63:\n",
      "action=1, reward=-1, new_state=91\n",
      "-1.83236579197=(1-0.7)*-1.7983292298999998+0.7*(-1+0.681*-1.24369)\n",
      "+---------+\n",
      "|R: | : :\u001b[43mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 64:\n",
      "action=2, reward=-1, new_state=91\n",
      "-1.665974023=(1-0.7)*-1.24369+0.7*(-1+0.681*-1.24369)\n",
      "+---------+\n",
      "|R: | : :\u001b[43mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 65:\n",
      "action=3, reward=-1, new_state=71\n",
      "-1.7325950299000001=(1-0.7)*-1.3066900000000001+0.7*(-1+0.681*-1.343797)\n",
      "+---------+\n",
      "|R: | :\u001b[43m \u001b[0m:G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 66:\n",
      "action=2, reward=-1, new_state=91\n",
      "-1.8973089167641=(1-0.7)*-1.343797+0.7*(-1+0.681*-1.665974023)\n",
      "+---------+\n",
      "|R: | : :\u001b[43mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 67:\n",
      "action=1, reward=-1, new_state=91\n",
      "-1.9939620236641=(1-0.7)*-1.665974023+0.7*(-1+0.681*-1.665974023)\n",
      "+---------+\n",
      "|R: | : :\u001b[43mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 68:\n",
      "action=2, reward=-1, new_state=91\n",
      "-1.9939620236641=(1-0.7)*-1.665974023+0.7*(-1+0.681*-1.665974023)\n",
      "+---------+\n",
      "|R: | : :\u001b[43mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 69:\n",
      "action=3, reward=-1, new_state=71\n",
      "-1.8603665388700001=(1-0.7)*-1.7325950299000001+0.7*(-1+0.681*-1.343797)\n",
      "+---------+\n",
      "|R: | :\u001b[43m \u001b[0m:G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 70:\n",
      "action=3, reward=-1, new_state=51\n",
      "-1.6960061229999999=(1-0.7)*-1.343797+0.7*(-1+0.681*-1.24369)\n",
      "+---------+\n",
      "|R: |\u001b[43m \u001b[0m: :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 71:\n",
      "action=1, reward=-1, new_state=51\n",
      "-1.665974023=(1-0.7)*-1.24369+0.7*(-1+0.681*-1.24369)\n",
      "+---------+\n",
      "|R: |\u001b[43m \u001b[0m: :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 72:\n",
      "action=5, reward=-10, new_state=51\n",
      "-10.422974023=(1-0.7)*-9.433689999999999+0.7*(-10+0.681*-1.24369)\n",
      "+---------+\n",
      "|R: |\u001b[43m \u001b[0m: :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "Step 73:\n",
      "action=2, reward=-1, new_state=71\n",
      "-1.82008074094=(1-0.7)*-1.24369+0.7*(-1+0.681*-1.5669681999999998)\n",
      "+---------+\n",
      "|R: | :\u001b[43m \u001b[0m:G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 74:\n",
      "action=0, reward=-1, new_state=171\n",
      "-1.9165392698641=(1-0.7)*-1.5669681999999998+0.7*(-1+0.681*-1.565867023)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : :\u001b[43m \u001b[0m: |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 75:\n",
      "action=1, reward=-1, new_state=71\n",
      "-1.9639299236641001=(1-0.7)*-1.565867023+0.7*(-1+0.681*-1.665974023)\n",
      "+---------+\n",
      "|R: | :\u001b[43m \u001b[0m:G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 76:\n",
      "action=1, reward=-1, new_state=71\n",
      "-1.9939620236641=(1-0.7)*-1.665974023+0.7*(-1+0.681*-1.665974023)\n",
      "+---------+\n",
      "|R: | :\u001b[43m \u001b[0m:G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 77:\n",
      "action=3, reward=-1, new_state=51\n",
      "-1.8794219668=(1-0.7)*-1.6960061229999999+0.7*(-1+0.681*-1.406797)\n",
      "+---------+\n",
      "|R: |\u001b[43m \u001b[0m: :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 78:\n",
      "action=1, reward=-1, new_state=51\n",
      "-1.8704123368=(1-0.7)*-1.665974023+0.7*(-1+0.681*-1.406797)\n",
      "+---------+\n",
      "|R: |\u001b[43m \u001b[0m: :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 79:\n",
      "action=3, reward=-1, new_state=51\n",
      "-1.7926592299000002=(1-0.7)*-1.406797+0.7*(-1+0.681*-1.406797)\n",
      "+---------+\n",
      "|R: |\u001b[43m \u001b[0m: :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 80:\n",
      "action=0, reward=-1, new_state=151\n",
      "-1.8373709598999999=(1-0.7)*-1.525804+0.7*(-1+0.681*-1.425697)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 81:\n",
      "action=0, reward=-1, new_state=251\n",
      "-2.0568805607003293=(1-0.7)*-1.9112228159233302+0.7*(-1+0.681*-1.6436201299)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 82:\n",
      "action=2, reward=-1, new_state=271\n",
      "-1.9114271757699999=(1-0.7)*-1.6436201299+0.7*(-1+0.681*-1.506904)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : :\u001b[43m \u001b[0m: |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 83:\n",
      "action=2, reward=-1, new_state=291\n",
      "-1.94729743492333=(1-0.7)*-1.506904+0.7*(-1+0.681*-1.6681901299000002)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : :\u001b[43m \u001b[0m|\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 84:\n",
      "action=0, reward=-1, new_state=391\n",
      "-1.8710771688700003=(1-0.7)*-1.6681901299000002+0.7*(-1+0.681*-1.406797)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | :\u001b[43m \u001b[0m|\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 85:\n",
      "action=0, reward=-1, new_state=491\n",
      "-1.7539478530000001=(1-0.7)*-1.406797+0.7*(-1+0.681*-1.32559)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Step 86:\n",
      "action=1, reward=-1, new_state=391\n",
      "-1.96478520784=(1-0.7)*-1.7737592299+0.7*(-1+0.681*-1.5369361)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | :\u001b[43m \u001b[0m|\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 87:\n",
      "action=3, reward=-1, new_state=371\n",
      "-1.9075296398641=(1-0.7)*-1.5369361+0.7*(-1+0.681*-1.565867023)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : |\u001b[43m \u001b[0m: |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 88:\n",
      "action=4, reward=-10, new_state=371\n",
      "-11.0244634479511=(1-0.7)*-10.926715460290001+0.7*(-10+0.681*-1.565867023)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : |\u001b[43m \u001b[0m: |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 89:\n",
      "action=2, reward=-1, new_state=391\n",
      "-1.9639299236641001=(1-0.7)*-1.565867023+0.7*(-1+0.681*-1.665974023)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | :\u001b[43m \u001b[0m|\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 90:\n",
      "action=2, reward=-1, new_state=391\n",
      "-1.9939620236641=(1-0.7)*-1.665974023+0.7*(-1+0.681*-1.665974023)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | :\u001b[43m \u001b[0m|\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 91:\n",
      "action=0, reward=-1, new_state=491\n",
      "-1.8580931089000001=(1-0.7)*-1.7539478530000001+0.7*(-1+0.681*-1.32559)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Step 92:\n",
      "action=0, reward=-1, new_state=491\n",
      "-1.729585753=(1-0.7)*-1.32559+0.7*(-1+0.681*-1.32559)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (South)\n",
      "Step 93:\n",
      "action=2, reward=-1, new_state=491\n",
      "-1.7926592299000002=(1-0.7)*-1.406797+0.7*(-1+0.681*-1.406797)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "  (East)\n",
      "Step 94:\n",
      "action=3, reward=-1, new_state=471\n",
      "-1.9996320236641=(1-0.7)*-1.6848740229999999+0.7*(-1+0.681*-1.665974023)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35m\u001b[43mB\u001b[0m\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 95:\n",
      "action=0, reward=-1, new_state=471\n",
      "-2.0880092681161=(1-0.7)*-1.97946483784+0.7*(-1+0.681*-1.665974023)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35m\u001b[43mB\u001b[0m\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 96:\n",
      "action=4, reward=-10, new_state=471\n",
      "-10.654308916764101=(1-0.7)*-9.533797+0.7*(-10+0.681*-1.665974023)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35m\u001b[43mB\u001b[0m\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 97:\n",
      "action=3, reward=-1, new_state=471\n",
      "-1.9939620236641=(1-0.7)*-1.665974023+0.7*(-1+0.681*-1.665974023)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35m\u001b[43mB\u001b[0m\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 98:\n",
      "action=0, reward=-1, new_state=471\n",
      "-2.18096343532816=(1-0.7)*-2.0880092681161+0.7*(-1+0.681*-1.7926592299)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35m\u001b[43mB\u001b[0m\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 99:\n",
      "action=1, reward=-1, new_state=371\n",
      "-2.09235842386333=(1-0.7)*-1.7926592299+0.7*(-1+0.681*-1.7926592299000002)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : |\u001b[43m \u001b[0m: |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "End episode 99! with sum_reward:-199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start episode 499:\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n",
      "state=108\n",
      "Step 0:\n",
      "action=0, reward=-1, new_state=208\n",
      "-0.09198431025094005=(1-0.7)*-0.09737882462172538+0.7*(-1+0.681*1.3367512841107143)\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 1:\n",
      "action=0, reward=-1, new_state=308\n",
      "1.3367540868260461=(1-0.7)*1.3367512841107143+0.7*(-1+0.681*3.4313587195150657)\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m| : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 2:\n",
      "action=0, reward=-1, new_state=408\n",
      "3.431359806334133=(1-0.7)*3.4313587195150657+0.7*(-1+0.681*6.507136963456289)\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1m\u001b[43mY\u001b[0m\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 3:\n",
      "action=4, reward=-1, new_state=416\n",
      "6.507137448525474=(1-0.7)*6.507136963456289+0.7*(-1+0.681*11.023696999136956)\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[42mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 4:\n",
      "action=1, reward=-1, new_state=316\n",
      "11.023697275743872=(1-0.7)*11.023696999136956+0.7*(-1+0.681*17.65594331026387)\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "|\u001b[42m_\u001b[0m| : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 5:\n",
      "action=1, reward=-1, new_state=216\n",
      "17.655943492762216=(1-0.7)*17.65594331026387+0.7*(-1+0.681*27.394924480140663)\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 6:\n",
      "action=1, reward=-1, new_state=116\n",
      "27.39492459719526=(1-0.7)*27.394924480140663+0.7*(-1+0.681*41.695924592307655)\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 7:\n",
      "action=1, reward=-1, new_state=16\n",
      "41.695924630845354=(1-0.7)*41.695924592307655+0.7*(-1+0.681*62.695924592307655)\n",
      "+---------+\n",
      "|\u001b[35m\u001b[42mR\u001b[0m\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 8:\n",
      "action=5, reward=20, new_state=16\n",
      "62.695924630845354=(1-0.7)*62.695924592307655+0.7*(20+0.681*62.695924592307655)\n",
      "+---------+\n",
      "|\u001b[35m\u001b[42mR\u001b[0m\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "End episode 499! with sum_reward:12\n",
      "Start episode 999:\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : : :\u001b[43m \u001b[0m: |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n",
      "state=168\n",
      "Step 0:\n",
      "action=3, reward=-1, new_state=148\n",
      "-2.30207085647032=(1-0.7)*-2.6028508967173547+0.7*(-1+0.681*-1.722709434560759)\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 1:\n",
      "action=0, reward=-1, new_state=248\n",
      "-1.7226221766220022=(1-0.7)*-1.722709434560759+0.7*(-1+0.681*-1.061064288344398)\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 2:\n",
      "action=3, reward=-1, new_state=228\n",
      "-1.0610642883020112=(1-0.7)*-1.061064288344398+0.7*(-1+0.681*-0.08966855841974372)\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 3:\n",
      "action=3, reward=-1, new_state=208\n",
      "-0.08966855841974351=(1-0.7)*-0.08966855841974372+0.7*(-1+0.681*1.336756889251478)\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "Step 4:\n",
      "action=0, reward=-1, new_state=308\n",
      "1.336756889251478=(1-0.7)*1.336756889251478+0.7*(-1+0.681*3.431361070853859)\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m| : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 5:\n",
      "action=0, reward=-1, new_state=408\n",
      "3.431361070853859=(1-0.7)*3.431361070853859+0.7*(-1+0.681*6.50713813634928)\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1m\u001b[43mY\u001b[0m\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 6:\n",
      "action=4, reward=-1, new_state=416\n",
      "6.50713813634928=(1-0.7)*6.50713813634928+0.7*(-1+0.681*11.023697703890278)\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[42mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 7:\n",
      "action=1, reward=-1, new_state=316\n",
      "11.023697703890278=(1-0.7)*11.023697703890278+0.7*(-1+0.681*17.655943764890278)\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "|\u001b[42m_\u001b[0m| : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 8:\n",
      "action=1, reward=-1, new_state=216\n",
      "17.655943764890278=(1-0.7)*17.655943764890278+0.7*(-1+0.681*27.394924764890273)\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 9:\n",
      "action=1, reward=-1, new_state=116\n",
      "27.394924764890273=(1-0.7)*27.394924764890273+0.7*(-1+0.681*41.695924764890265)\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 10:\n",
      "action=1, reward=-1, new_state=16\n",
      "41.695924764890265=(1-0.7)*41.695924764890265+0.7*(-1+0.681*62.695924764890265)\n",
      "+---------+\n",
      "|\u001b[35m\u001b[42mR\u001b[0m\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 11:\n",
      "action=5, reward=20, new_state=16\n",
      "62.695924764890265=(1-0.7)*62.695924764890265+0.7*(20+0.681*62.695924764890265)\n",
      "+---------+\n",
      "|\u001b[35m\u001b[42mR\u001b[0m\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "End episode 999! with sum_reward:9\n",
      "Start episode 49999:\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m| : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "\n",
      "state=311\n",
      "Step 0:\n",
      "action=0, reward=-1, new_state=411\n",
      "-1.0610642882838452=(1-0.7)*-1.0610642882838452+0.7*(-1+0.681*-0.08966855841974342)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1m\u001b[43mY\u001b[0m\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 1:\n",
      "action=4, reward=-1, new_state=419\n",
      "-0.08966855841974342=(1-0.7)*-0.08966855841974342+0.7*(-1+0.681*1.336756889251478)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[42mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "Step 2:\n",
      "action=1, reward=-1, new_state=319\n",
      "1.336756889251478=(1-0.7)*1.336756889251478+0.7*(-1+0.681*3.431361070853859)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "|\u001b[42m_\u001b[0m| : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 3:\n",
      "action=1, reward=-1, new_state=219\n",
      "3.431361070853859=(1-0.7)*3.431361070853859+0.7*(-1+0.681*6.50713813634928)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "Step 4:\n",
      "action=2, reward=-1, new_state=239\n",
      "6.50713813634928=(1-0.7)*6.50713813634928+0.7*(-1+0.681*11.023697703890278)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| :\u001b[42m_\u001b[0m: : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 5:\n",
      "action=2, reward=-1, new_state=259\n",
      "11.023697703890278=(1-0.7)*11.023697703890278+0.7*(-1+0.681*17.655943764890278)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : :\u001b[42m_\u001b[0m: : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 6:\n",
      "action=2, reward=-1, new_state=279\n",
      "17.655943764890278=(1-0.7)*17.655943764890278+0.7*(-1+0.681*27.394924764890273)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : :\u001b[42m_\u001b[0m: |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "Step 7:\n",
      "action=0, reward=-1, new_state=379\n",
      "27.394924764890273=(1-0.7)*27.394924764890273+0.7*(-1+0.681*41.695924764890265)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : |\u001b[42m_\u001b[0m: |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 8:\n",
      "action=0, reward=-1, new_state=479\n",
      "41.695924764890265=(1-0.7)*41.695924764890265+0.7*(-1+0.681*62.695924764890265)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35m\u001b[42mB\u001b[0m\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "Step 9:\n",
      "action=5, reward=20, new_state=479\n",
      "62.695924764890265=(1-0.7)*62.695924764890265+0.7*(20+0.681*62.695924764890265)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35m\u001b[42mB\u001b[0m\u001b[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "End episode 49999! with sum_reward:11\n"
     ]
    }
   ],
   "source": [
    "traning(50000, 100, 0.7, 0.681, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [ -1.06106789,  -0.08984107,  -2.17716929,  -0.11085477,\n",
       "          1.33675689,  -9.08966898],\n",
       "       [  1.33431743,   3.43099769,   1.3367343 ,   3.43099302,\n",
       "          6.50713814,  -5.56867113],\n",
       "       ...,\n",
       "       [ -2.03196759,   3.20579081,  -1.99396202,  -2.07793538,\n",
       "         -9.73      , -10.52416982],\n",
       "       [ -2.63105407,  -0.09181404,  -1.64739908,  -2.69892435,\n",
       "        -11.07588497, -10.54749575],\n",
       "       [ -0.7       ,  -0.7       ,  -0.7       ,  41.69592476,\n",
       "         -7.        ,   0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start episode 0:\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m| : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n",
      "step 0:\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1m\u001b[43mY\u001b[0m\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "step 1:\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[42mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "step 2:\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "|\u001b[42m_\u001b[0m| : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "step 3:\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "step 4:\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "step 5:\n",
      "+---------+\n",
      "|\u001b[35m\u001b[42mR\u001b[0m\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "step 6:\n",
      "+---------+\n",
      "|\u001b[35m\u001b[42mR\u001b[0m\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "End episode 0! with sum_reward=14\n"
     ]
    }
   ],
   "source": [
    "playing(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m| : | : |\n",
      "|\u001b[35mY\u001b[0m| : |\u001b[34;1mB\u001b[0m: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
